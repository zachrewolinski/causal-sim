{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlp import get_batch\n",
    "from torch.nn import Sigmoid\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def truncate(pscores, thresh):\n",
    "    return np.clip(pscores, thresh, 1 - thresh)\n",
    "\n",
    "def ipw_ht(Z, Y, pscores):\n",
    "\n",
    "    weights = Z / pscores + (1 - Z) / (1 - pscores)\n",
    "\n",
    "    output = np.sum(weights * Y) / np.sum(weights)\n",
    "    return output\n",
    "\n",
    "\n",
    "def ipw_hayek(Z, Y, pscores):\n",
    "\n",
    "    t1 = Z / pscores\n",
    "    t2 = (1 - Z) / (1 - pscores)\n",
    "\n",
    "    return np.sum(t1 * Y) / np.sum(t1) - np.sum(t2 * Y) / np.sum(t2)\n",
    "\n",
    "hyperparameters = {\n",
    "    \"is_causal\": True,\n",
    "    \"num_causes\": 8,\n",
    "    \"prior_mlp_hidden_dim\": 8,\n",
    "    \"num_layers\": 3,\n",
    "    \"noise_std\": 0.1,\n",
    "    \"y_is_effect\": True,\n",
    "    \"pre_sample_weights\": False,\n",
    "    \"prior_mlp_dropout_prob\": 0.5,\n",
    "    \"pre_sample_causes\": False,\n",
    "    \"prior_mlp_activations\": Sigmoid,\n",
    "    \"block_wise_dropout\": True,\n",
    "    \"init_std\": 1.0,\n",
    "    'prior_mlp_scale_weights_sqrt': True,\n",
    "    'sampling': 'normal',\n",
    "    'in_clique': False,\n",
    "    'sort_features': False,\n",
    "    'random_feature_rotation': False,\n",
    "    'new_mlp_per_example': True\n",
    "} \n",
    "\n",
    "x, y, _ = get_batch(batch_size=100, seq_len=10000, num_features=8, hyperparameters=hyperparameters,\n",
    "          num_outputs=3, sampling=\"mixed\")\n",
    "x = x.numpy()\n",
    "y = y.numpy()\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "plt.scatter(x[:,0,0], x[:,0,1], c=y[:,0,0], s=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATEs = []\n",
    "ATE_hayeks = []\n",
    "for i in range(100):\n",
    "    X = x[:,i,:]\n",
    "    Y0 = y[:,i,0]\n",
    "    Z = y[:,i,1]\n",
    "    Z = Z > np.median(Z)\n",
    "    Y1 = Y0 + 1#np.abs(y[:,i,2]) # 1\n",
    "    Y = np.where(Z, Y1, Y0)\n",
    "    ATE = np.mean(Y1) - np.mean(Y0)\n",
    "    # print(ATE)\n",
    "    ATEs.append(ATE)\n",
    "\n",
    "    pscore_model = LogisticRegression()\n",
    "    pscore_model.fit(X, Z)\n",
    "    pscores = pscore_model.predict_proba(X)[:, 1]\n",
    "    pscores = truncate(pscores, 0.01)\n",
    "\n",
    "    ATE_hayek = ipw_hayek(Z, Y, pscores)\n",
    "    ATE_hayeks.append(ATE_hayek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pscores[Z==0], histtype='step')\n",
    "plt.hist(pscores[Z==1], histtype='step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ATEs, ATE_hayeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ATE_hayeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"is_causal\": True,\n",
    "    \"num_causes\": 8,\n",
    "    \"prior_mlp_hidden_dim\": 3,\n",
    "    \"num_layers\": 2,\n",
    "    \"noise_std\": 0.1,\n",
    "    \"y_is_effect\": True,\n",
    "    \"pre_sample_weights\": False,\n",
    "    \"prior_mlp_dropout_prob\": 0.5,\n",
    "    \"pre_sample_causes\": False,\n",
    "    \"prior_mlp_activations\": Sigmoid,\n",
    "    \"block_wise_dropout\": False,\n",
    "    \"init_std\": 1.0,\n",
    "    'prior_mlp_scale_weights_sqrt': True,\n",
    "    'sampling': 'normal',\n",
    "    'in_clique': False,\n",
    "    'sort_features': False,\n",
    "    'random_feature_rotation': False,\n",
    "    'new_mlp_per_example': True\n",
    "} \n",
    "\n",
    "_, x, _ = get_batch(batch_size=100, seq_len=10000, num_features=8, hyperparameters=hyperparameters,\n",
    "          num_outputs=5, sampling=\"mixed\")\n",
    "_, u, _ = get_batch(batch_size=100, seq_len=10000, num_features=8, hyperparameters=hyperparameters,\n",
    "          num_outputs=3, sampling=\"mixed\")\n",
    "\n",
    "# x = x.numpy()\n",
    "# u = u.numpy()\n",
    "x = x.detach()\n",
    "u = u.detach()\n",
    "\n",
    "# print(x.shape, y.shape)\n",
    "\n",
    "# plt.scatter(x[:,0,0], x[:,0,1], c=y[:,0,0], s=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list of 10000 x, u pairs\n",
    "causes = [[x[:,i,np.newaxis,:], u[:,i,np.newaxis,:]] for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, y, _ = get_batch(batch_size=100, seq_len=10000, num_features=8, hyperparameters=hyperparameters,\n",
    "          num_outputs=2, sampling=\"mixed\", causes=causes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rands = np.random.normal(0, 1, size=(10000, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.corrcoef(y[:,0,0], rands[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(y[:,0,0], x[:,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(y[:,0,0], u[:,0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y[:,0,0], x[:,0,0], s=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y[:,0,0], u[:,0,2], s=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal-sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
